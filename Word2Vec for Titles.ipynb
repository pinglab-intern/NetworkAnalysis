{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "#import scikitplot.plotters as skplt\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.markers import MarkerStyle\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48470</th>\n",
       "      <td>10694616</td>\n",
       "      <td>[result, revascularization, patients, severe, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48471</th>\n",
       "      <td>25746522</td>\n",
       "      <td>[diastolic, dysfunction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48473</th>\n",
       "      <td>3963944</td>\n",
       "      <td>[clinical, experience, timolol, maleate, monot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48477</th>\n",
       "      <td>29524314</td>\n",
       "      <td>[semaphorin, level, heart, failure, patients, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48478</th>\n",
       "      <td>12008175</td>\n",
       "      <td>[effect, perindopril, aldosterone, production,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pmid                                              title\n",
       "48470  10694616  [result, revascularization, patients, severe, ...\n",
       "48471  25746522                           [diastolic, dysfunction]\n",
       "48473   3963944  [clinical, experience, timolol, maleate, monot...\n",
       "48477  29524314  [semaphorin, level, heart, failure, patients, ...\n",
       "48478  12008175  [effect, perindopril, aldosterone, production,..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json as json\n",
    "import pandas as pd\n",
    "\n",
    "## Get the Data\n",
    "\n",
    "with open(\"data/icd2pmid.json\", 'r') as f:\n",
    "    Data_pmid =  json.load(f)\n",
    "\n",
    "heart_pmid = Data_pmid['heart failure']\n",
    "\n",
    "with open(\"data/cvddocs.json\", 'r') as f:\n",
    "    Data_title =  json.load(f)\n",
    "\n",
    "# creating a list with title and pmid\n",
    "title = []\n",
    "for item in Data_title:\n",
    "    #print(item)\n",
    "    title.append({\"pmid\": item['pmid'], \"title\": item['title']})\n",
    "\n",
    "# converting list to dataframe\n",
    "title_df = pd.DataFrame(title)\n",
    "\n",
    "title_df = title_df[title_df['pmid'].isin(heart_pmid)]\n",
    "title_df = title_df.reset_index(drop=True)\n",
    "title_df = title_df.drop_duplicates('pmid', keep = False)\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def clean_text(text):\n",
    "    #Convert to lower case\n",
    "    text = text.lower()\n",
    "    #Lemmatizing the text\n",
    "    lemma = WordNetLemmatizer()\n",
    "    normalized = \" \".join(lemma.lemmatize(word, pos = \"v\") for word in text.split())\n",
    "    #Removing White spaces\n",
    "    normalized = normalized.replace('\\d+', '')\n",
    "    normalized = normalized.strip()\n",
    "    #Tokenize and extract words that are alpha-numeric\n",
    "    tokens = word_tokenize(normalized)\n",
    "    cleaned = [word for word in tokens if word.isalpha()]\n",
    "    #Create a dictionary of stem-words such as \"at\" and \n",
    "    #\"the\" that don't contribute to meaning and remove them from the list\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in cleaned if not w in stop_words]\n",
    "    #Remove punctuations\n",
    "    #exclude = set(string.punctuation)\n",
    "    #punc_free = [ch for ch in stop_words if ch not in exclude]\n",
    "    return words\n",
    "\n",
    "title_df[\"title\"] = [clean_text(text) for text in title_df[\"title\"]]\n",
    "title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heart</td>\n",
       "      <td>30633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>failure</td>\n",
       "      <td>27044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patients</td>\n",
       "      <td>13845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardiac</td>\n",
       "      <td>7206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chronic</td>\n",
       "      <td>6328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ventricular</td>\n",
       "      <td>5479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leave</td>\n",
       "      <td>4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>effect</td>\n",
       "      <td>3863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>study</td>\n",
       "      <td>3848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>disease</td>\n",
       "      <td>3736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  count\n",
       "0        heart  30633\n",
       "1      failure  27044\n",
       "2     patients  13845\n",
       "3      cardiac   7206\n",
       "4      chronic   6328\n",
       "5  ventricular   5479\n",
       "6        leave   4384\n",
       "7       effect   3863\n",
       "8        study   3848\n",
       "9      disease   3736"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "title_list = itertools.chain(title_df['title'])\n",
    "title_list = list(title_list)\n",
    "flattened = [val for sublist in title_list for val in sublist]\n",
    "counts = Counter(flattened)\n",
    "df_counts = pd.DataFrame.from_dict(counts, orient='index').reset_index()\n",
    "df_counts.columns = ['word', 'count']\n",
    "df_counts = df_counts.sort_values(['count'], ascending=[False])\n",
    "df_counts = df_counts.reset_index(drop=True)\n",
    "df_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts['rel_freq'] = df_counts['count']/sum(df_counts['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_words = df_counts[df_counts['count'] > 100]\n",
    "keep_words = keep_words['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48470</td>\n",
       "      <td>10694616</td>\n",
       "      <td>[result, revascularization, patients, severe, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48471</td>\n",
       "      <td>25746522</td>\n",
       "      <td>[diastolic, dysfunction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48473</td>\n",
       "      <td>3963944</td>\n",
       "      <td>[clinical, experience, hypertension]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48477</td>\n",
       "      <td>29524314</td>\n",
       "      <td>[level, heart, failure, patients, potential, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48478</td>\n",
       "      <td>12008175</td>\n",
       "      <td>[effect, aldosterone, production, fail, human,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48480</td>\n",
       "      <td>21080863</td>\n",
       "      <td>[change, blood, pressure, acute, heart, failur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48481</td>\n",
       "      <td>29202359</td>\n",
       "      <td>[intravenous, administration, rat, chronic, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48486</td>\n",
       "      <td>16555861</td>\n",
       "      <td>[mechanisms, management, digoxin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48490</td>\n",
       "      <td>21140063</td>\n",
       "      <td>[heart, energy, metabolism, role, treatment, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48491</td>\n",
       "      <td>12385167</td>\n",
       "      <td>[status, outcomes, disease, management, progra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      pmid                                              title\n",
       "0  48470  10694616  [result, revascularization, patients, severe, ...\n",
       "1  48471  25746522                           [diastolic, dysfunction]\n",
       "2  48473   3963944               [clinical, experience, hypertension]\n",
       "3  48477  29524314  [level, heart, failure, patients, potential, n...\n",
       "4  48478  12008175  [effect, aldosterone, production, fail, human,...\n",
       "5  48480  21080863  [change, blood, pressure, acute, heart, failur...\n",
       "6  48481  29202359  [intravenous, administration, rat, chronic, he...\n",
       "7  48486  16555861                  [mechanisms, management, digoxin]\n",
       "8  48490  21140063  [heart, energy, metabolism, role, treatment, h...\n",
       "9  48491  12385167  [status, outcomes, disease, management, progra..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_words = list(keep_words)\n",
    "def list_comp(text):\n",
    "    return [x for x in text if x in keep_words]\n",
    "\n",
    "title_df[\"title\"] = [list_comp(text) for text in title_df[\"title\"]]\n",
    "title_df.reset_index(inplace = True) \n",
    "title_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from w2vec_helper import preprocess,token_lookup,create_lookup_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 461420\n",
      "Unique words: 4692\n",
      "['result', 'revascularization', 'patients', 'severe', 'leave', 'ventricular', 'dysfunction', 'diastolic', 'dysfunction', 'clinical', 'experience', 'monotherapy', 'hypertension', 'level', 'heart', 'failure', 'patients', 'potential', 'novel', 'biomarker', 'acute', 'heart', 'failure', 'effect', 'perindopril', 'aldosterone', 'production', 'fail', 'human', 'heart']\n"
     ]
    }
   ],
   "source": [
    "all_txt = \" \".join([wd for wd in flattened])\n",
    "            \n",
    "words = preprocess(all_txt)\n",
    "print(\"Total words: {}\".format(len(words)))\n",
    "print(\"Unique words: {}\".format(len(set(words))))\n",
    "print(words[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int, int_to_vocab = create_lookup_tables(words)\n",
    "int_words = [vocab_to_int[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "threshold = 1e-5\n",
    "word_counts = Counter(int_words)\n",
    "total_count = len(int_words)\n",
    "freqs = {word: count/total_count for word, count in word_counts.items()}\n",
    "p_drop = {word: 1 - np.sqrt(threshold/freqs[word]) for word in word_counts}\n",
    "train_words = [word for word in int_words if random.random() < (1 - p_drop[word])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(words, idx, window_size=5):\n",
    "    ''' Get a list of words in a window around an index. '''\n",
    "    \n",
    "    R = np.random.randint(1, window_size+1)\n",
    "    start = idx - R if (idx - R) > 0 else 0\n",
    "    stop = idx + R\n",
    "    target_words = set(words[start:idx] + words[idx+1:stop+1])\n",
    "    \n",
    "    return list(target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(words, batch_size, window_size=5):\n",
    "    ''' Create a generator of word batches as a tuple (inputs, targets) '''\n",
    "    \n",
    "    n_batches = len(words)//batch_size\n",
    "    \n",
    "    # only full batches\n",
    "    words = words[:n_batches*batch_size]\n",
    "    \n",
    "    for idx in range(0, len(words), batch_size):\n",
    "        x, y = [], []\n",
    "        batch = words[idx:idx+batch_size]\n",
    "        for ii in range(len(batch)):\n",
    "            batch_x = batch[ii]\n",
    "            batch_y = get_target(batch, ii, window_size)\n",
    "            y.extend(batch_y)\n",
    "            x.extend([batch_x]*len(batch_y))\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    inputs = tf.placeholder(tf.int32, [None], name='inputs')\n",
    "    labels = tf.placeholder(tf.int32, [None, None], name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(int_to_vocab)\n",
    "n_embedding = 200 # Number of embedding features \n",
    "with train_graph.as_default():\n",
    "    embedding = tf.Variable(tf.random_uniform((n_vocab, n_embedding), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/caseolap/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:1344: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of negative labels to sample\n",
    "n_sampled = 100\n",
    "with train_graph.as_default():\n",
    "    softmax_w = tf.Variable(tf.truncated_normal((n_vocab, n_embedding), stddev=0.1))\n",
    "    softmax_b = tf.Variable(tf.zeros(n_vocab))\n",
    "    \n",
    "    # Calculate the loss using negative sampling\n",
    "    loss = tf.nn.sampled_softmax_loss(softmax_w, softmax_b, \n",
    "                                      labels, embed,\n",
    "                                      n_sampled, n_vocab)\n",
    "    \n",
    "    cost = tf.reduce_mean(loss)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-75206e3a5b09>:13: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "with train_graph.as_default():\n",
    "    ## From Thushan Ganegedara's implementation\n",
    "    valid_size = 16 # Random set of words to evaluate similarity on.\n",
    "    valid_window = 100\n",
    "    # pick 8 samples from (0,100) and (1000,1100) each ranges. lower id implies more frequent \n",
    "    valid_examples = np.array(random.sample(range(valid_window), valid_size//2))\n",
    "    valid_examples = np.append(valid_examples, \n",
    "                               random.sample(range(1000,1000+valid_window), valid_size//2))\n",
    "\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    # We use the cosine distance:\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embedding), 1, keep_dims=True))\n",
    "    normalized_embedding = embedding / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# If the checkpoints directory doesn't exist:\n",
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Iteration: 100 Avg. Training loss: 4.9495 0.0253 sec/batch\n",
      "Epoch 4/10 Iteration: 200 Avg. Training loss: 4.8479 0.0015 sec/batch\n",
      "Epoch 5/10 Iteration: 300 Avg. Training loss: 4.7520 0.0269 sec/batch\n",
      "Epoch 7/10 Iteration: 400 Avg. Training loss: 4.6756 0.0030 sec/batch\n",
      "Epoch 8/10 Iteration: 500 Avg. Training loss: 4.5989 0.0283 sec/batch\n",
      "Epoch 10/10 Iteration: 600 Avg. Training loss: 4.5003 0.0045 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 1000\n",
    "window_size = 10\n",
    "\n",
    "with train_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    iteration = 1\n",
    "    loss = 0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        batches = get_batches(train_words, batch_size, window_size)\n",
    "        start = time.time()\n",
    "        for x, y in batches:\n",
    "            \n",
    "            feed = {inputs: x,\n",
    "                    labels: np.array(y)[:, None]}\n",
    "            train_loss, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "            \n",
    "            loss += train_loss\n",
    "            \n",
    "            if iteration % 100 == 0: \n",
    "                end = time.time()\n",
    "                print(\"Epoch {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Avg. Training loss: {:.4f}\".format(loss/100),\n",
    "                      \"{:.4f} sec/batch\".format((end-start)/100))\n",
    "                loss = 0\n",
    "                start = time.time()\n",
    "                \n",
    "            if iteration % 1000 == 0:\n",
    "                # note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "                sim = similarity.eval()\n",
    "                for i in range(valid_size):\n",
    "                    valid_word = int_to_vocab[valid_examples[i]]\n",
    "                    top_k = 8 # number of nearest neighbors\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                    log = 'Nearest to %s:' % valid_word\n",
    "                    for k in range(top_k):\n",
    "                        close_word = int_to_vocab[nearest[k]]\n",
    "                        log = '%s %s,' % (log, close_word)\n",
    "                    print(log)\n",
    "            \n",
    "            iteration += 1\n",
    "    save_path = saver.save(sess, \"checkpoints/text8.ckpt\")\n",
    "    embed_mat = sess.run(normalized_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/text8.ckpt\n"
     ]
    }
   ],
   "source": [
    "with train_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    embed_mat = sess.run(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.38370183  0.62634724 -0.01755597 ...  0.15212269 -0.5455985\n",
      "   0.22186518]\n",
      " [-0.3499129  -0.3837383   0.73370355 ...  0.833947    0.14912339\n",
      "  -0.75480413]\n",
      " [ 0.01575112 -0.44451842 -0.19250113 ...  0.00424699 -0.28120068\n",
      "   0.13040693]\n",
      " ...\n",
      " [-0.3695202  -0.99509495  0.5127186  ...  0.8638124   0.3259946\n",
      "  -0.28194782]\n",
      " [ 0.78613424 -0.06840792  0.68068725 ...  0.5955178  -0.7683486\n",
      "  -0.11095252]\n",
      " [-0.59153724 -0.62557    -0.19154978 ... -0.01748623  0.07661288\n",
      "  -0.8053517 ]]\n"
     ]
    }
   ],
   "source": [
    "print(embed_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4692, 200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.59153724, -0.62557   , -0.19154978,  0.9077609 , -0.4875117 ,\n",
       "       -0.05857721, -0.7775072 , -0.39937663, -0.9316475 ,  0.75631523,\n",
       "       -0.09152687, -0.52588445, -0.83428675, -0.56277335,  0.24134283,\n",
       "        0.48273927,  0.6694711 , -0.07902664, -0.6406285 , -0.7445849 ,\n",
       "        0.77208906,  0.953192  , -0.24833632,  0.58251107, -0.2996608 ,\n",
       "       -0.3894344 , -0.5872499 ,  0.90599215, -0.34316316,  0.24182503,\n",
       "       -0.9237751 ,  0.5776705 ,  0.8524521 ,  0.6696428 , -0.6918856 ,\n",
       "       -0.45416665, -0.70951474,  0.10644202,  0.42990303,  0.85514194,\n",
       "        0.44066688, -0.3827289 , -0.02647946,  0.69514537, -0.2562705 ,\n",
       "        0.43391243, -0.95366085, -0.16764194, -0.96034676, -0.47389036,\n",
       "       -0.39404026, -0.19322473, -0.23624629, -0.6699079 ,  0.29834384,\n",
       "        0.48599827, -0.70355326,  0.43779343,  0.32674915,  0.0185207 ,\n",
       "        0.75192124,  0.62641305, -0.49355423, -0.9114425 ,  0.9456332 ,\n",
       "       -0.32953522,  0.862535  , -0.5511835 , -0.23035178, -0.6683906 ,\n",
       "       -0.84317625, -0.4599495 ,  0.9436384 ,  0.7139307 ,  0.61757964,\n",
       "       -0.8644137 ,  0.09566402,  0.7458316 ,  0.8452465 , -0.06942091,\n",
       "        0.04205341, -0.6237473 ,  0.5558368 ,  0.6733072 ,  0.90255797,\n",
       "        0.3633255 , -0.7571142 , -0.11949147, -0.52622503,  0.05453202,\n",
       "        0.8302707 , -0.36985692, -0.828859  , -0.06845402, -0.35862845,\n",
       "        0.05477476,  0.76246256, -0.28215632,  0.7477768 ,  0.43867967,\n",
       "        0.81537026, -0.33768684, -0.55246496, -0.17703478, -1.0445136 ,\n",
       "        0.9796867 ,  0.6068046 , -0.7823513 , -0.24995929,  0.39902642,\n",
       "       -0.4827955 ,  0.06493182, -0.87894994, -0.6461322 ,  0.4801799 ,\n",
       "       -0.48929557, -0.11329164, -0.3809098 ,  0.47061214, -0.70234984,\n",
       "       -0.69606555,  0.18531471, -0.84851027, -0.8792747 ,  0.37471005,\n",
       "       -0.17647685, -0.46150145,  0.08991155,  0.60817456, -0.28887698,\n",
       "        0.0285791 , -0.02011242,  0.37122405, -0.07519006, -0.8295078 ,\n",
       "        0.46832323,  0.25498328,  0.23461325, -0.88968295,  0.05292555,\n",
       "       -0.78059465, -0.38794857,  0.1110125 , -0.2386662 ,  0.4183223 ,\n",
       "       -0.05623872, -0.941476  , -0.07321569,  0.00601056, -0.78519696,\n",
       "       -0.58287627,  0.22390692,  0.1496887 ,  0.4075688 ,  0.7638559 ,\n",
       "        0.10246723,  0.25510734,  0.41033798, -0.37246218,  0.785567  ,\n",
       "        0.05289261,  0.7705618 , -1.0392383 , -0.53892356,  0.732242  ,\n",
       "        0.56580293, -0.28249335,  0.16656955,  0.40365997,  0.11486767,\n",
       "        0.8239519 , -0.00481483, -0.16538031, -0.931061  ,  0.4670737 ,\n",
       "       -0.14134948,  0.9690787 , -0.8008228 ,  0.9098156 , -0.43400866,\n",
       "        0.69457006, -0.14478064,  0.69991183,  0.3414029 ,  0.67678154,\n",
       "       -0.41581532, -0.717511  ,  0.10808229,  0.6903476 ,  0.59656024,\n",
       "       -0.4271361 ,  0.22145344, -0.71295553, -0.09420925,  0.54380506,\n",
       "       -0.97559005, -0.50285363, -0.01748623,  0.07661288, -0.8053517 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_mat[4691,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attend',\n",
       " 'construct',\n",
       " 'intravenous',\n",
       " 'core',\n",
       " 'tai',\n",
       " 'triatriatum',\n",
       " 'address',\n",
       " 'us',\n",
       " 'neurons',\n",
       " 'stable',\n",
       " 'macrovascular',\n",
       " 'bradykinin',\n",
       " 'cardiologists',\n",
       " 'match',\n",
       " 'drosophila',\n",
       " 'agonist',\n",
       " 'swiss',\n",
       " 'granulomatosis',\n",
       " 'interdisciplinary',\n",
       " 'present',\n",
       " 'biologic',\n",
       " 'injuries',\n",
       " 'ntprobnp',\n",
       " 'emergency',\n",
       " 'classic',\n",
       " 'molecule',\n",
       " 'class',\n",
       " 'doppler',\n",
       " 'neonate',\n",
       " 'chf',\n",
       " 'india',\n",
       " 'contemporary',\n",
       " 'ligands',\n",
       " 'vital',\n",
       " 'actual',\n",
       " 'cool',\n",
       " 'timing',\n",
       " 'italiano',\n",
       " 'require',\n",
       " 'isoproterenol',\n",
       " 'cannabinoid',\n",
       " 'inducible',\n",
       " 'combination',\n",
       " 'intracardiac',\n",
       " 'evidence',\n",
       " 'color',\n",
       " 'mobilize',\n",
       " 'bicycle',\n",
       " 'transfer',\n",
       " 'immunologic',\n",
       " 'thrombus',\n",
       " 'adjustments',\n",
       " 'cyst',\n",
       " 'g',\n",
       " 'bioelectrical',\n",
       " 'soul',\n",
       " 'furosemide',\n",
       " 'ectopic',\n",
       " 'similarities',\n",
       " 'nervous',\n",
       " 'attack',\n",
       " 'propensity',\n",
       " 'preoperative',\n",
       " 'get',\n",
       " 'readmissions',\n",
       " 'california',\n",
       " 'wearable',\n",
       " 'efficient',\n",
       " 'maneuver',\n",
       " 'titin',\n",
       " 'relationships',\n",
       " 'dipyridamole',\n",
       " 'oxygen',\n",
       " 'salt',\n",
       " 'hospital',\n",
       " 'dehiscence',\n",
       " 'orientation',\n",
       " 'cardiologist',\n",
       " 'powerful',\n",
       " 'comparison',\n",
       " 'mesenteric',\n",
       " 'immunoglobulin',\n",
       " 'apoptosis',\n",
       " 'atherosclerotic',\n",
       " 'pharmacist',\n",
       " 'correlations',\n",
       " 'like',\n",
       " 'native',\n",
       " 'think',\n",
       " 'transfemoral',\n",
       " 'fetalis',\n",
       " 'act',\n",
       " 'pet',\n",
       " 'discriminate',\n",
       " 'adaptation',\n",
       " 'genesis',\n",
       " 'cytosolic',\n",
       " 'questionnaires',\n",
       " 'situations',\n",
       " 'suppression',\n",
       " 'variations',\n",
       " 'cardiosclerosis',\n",
       " 'angioplasty',\n",
       " 'rare',\n",
       " 'within',\n",
       " 'especially',\n",
       " 'calculate',\n",
       " 'perfusion',\n",
       " 'cluster',\n",
       " 'peer',\n",
       " 'information',\n",
       " 'bare',\n",
       " 'reviews',\n",
       " 'carboxymaltose',\n",
       " 'levosimendan',\n",
       " 'race',\n",
       " 'tezosentan',\n",
       " 'gut',\n",
       " 'vasculitis',\n",
       " 'still',\n",
       " 'uhl',\n",
       " 'new',\n",
       " 'telemonitoring',\n",
       " 'dietary',\n",
       " 'severely',\n",
       " 'strong',\n",
       " 'costs',\n",
       " 'scaffold',\n",
       " 'predictor',\n",
       " 'asians',\n",
       " 'bioenergetics',\n",
       " 'input',\n",
       " 'defective',\n",
       " 'amrinone',\n",
       " 'augmentation',\n",
       " 'myocarditis',\n",
       " 'pimobendan',\n",
       " 'branch',\n",
       " 'peritoneal',\n",
       " 'monoamine',\n",
       " 'british',\n",
       " 'features',\n",
       " 'aneurysmal',\n",
       " 'renovascular',\n",
       " 'alert',\n",
       " 'appropriateness',\n",
       " 'vasodilator',\n",
       " 'coenzyme',\n",
       " 'hemodynamics',\n",
       " 'deaminase',\n",
       " 'bioprosthesis',\n",
       " 'breath',\n",
       " 'monoclonal',\n",
       " 'resolve',\n",
       " 'localize',\n",
       " 'inhibition',\n",
       " 'willebrand',\n",
       " 'elective',\n",
       " 'implication',\n",
       " 'adjunctive',\n",
       " 'uptake',\n",
       " 'congestion',\n",
       " 'sensor',\n",
       " 'water',\n",
       " 'china',\n",
       " 'deconditioning',\n",
       " 'ejection',\n",
       " 'coverage',\n",
       " 'anesthesia',\n",
       " 'lethal',\n",
       " 'conductance',\n",
       " 'clinicians',\n",
       " 'va',\n",
       " 'antioxidative',\n",
       " 'instrument',\n",
       " 'thromboembolism',\n",
       " 'every',\n",
       " 'multimorbidity',\n",
       " 'cardiac',\n",
       " 'erythropoiesis',\n",
       " 'epidemiology',\n",
       " 'genome',\n",
       " 'gestational',\n",
       " 'mobilization',\n",
       " 'kinin',\n",
       " 'epigenetic',\n",
       " 'graft',\n",
       " 'ultrafiltration',\n",
       " 'diaphragm',\n",
       " 'prostheses',\n",
       " 'chickens',\n",
       " 'pacing',\n",
       " 'regulate',\n",
       " 'period',\n",
       " 'subunits',\n",
       " 'downregulated',\n",
       " 'ryanodine',\n",
       " 'adhere',\n",
       " 'intrapericardial',\n",
       " 'directly',\n",
       " 'occlusion',\n",
       " 'cardiopathy',\n",
       " 'revisit',\n",
       " 'dog',\n",
       " 'limit',\n",
       " 'international',\n",
       " 'refractory',\n",
       " 'month',\n",
       " 'technology',\n",
       " 'hyperhomocysteinemia',\n",
       " 'intact',\n",
       " 'counteract',\n",
       " 'transvenous',\n",
       " 'multivariate',\n",
       " 'robust',\n",
       " 'flutter',\n",
       " 'logistic',\n",
       " 'dead',\n",
       " 'qi',\n",
       " 'angiosarcoma',\n",
       " 'synthase',\n",
       " 'comment',\n",
       " 'cvd',\n",
       " 'subgroups',\n",
       " 'ampk',\n",
       " 'office',\n",
       " 'hypocalcemia',\n",
       " 'scottish',\n",
       " 'receptors',\n",
       " 'force',\n",
       " 'predominantly',\n",
       " 'anchor',\n",
       " 'executive',\n",
       " 'peculiarities',\n",
       " 'mouse',\n",
       " 'enos',\n",
       " 'persistent',\n",
       " 'instrumental',\n",
       " 'digitoxin',\n",
       " 'multisite',\n",
       " 'practice',\n",
       " 'pseudoaneurysm',\n",
       " 'descend',\n",
       " 'cohort',\n",
       " 'box',\n",
       " 'complications',\n",
       " 'north',\n",
       " 'open',\n",
       " 'record',\n",
       " 'users',\n",
       " 'haemoglobin',\n",
       " 'consistency',\n",
       " 'transapical',\n",
       " 'typical',\n",
       " 'heterotopic',\n",
       " 'profound',\n",
       " 'catecholamine',\n",
       " 'longevity',\n",
       " 'monophosphate',\n",
       " 'doxazosin',\n",
       " 'bovine',\n",
       " 'prosthetic',\n",
       " 'individuals',\n",
       " 'disseminate',\n",
       " 'fluctuations',\n",
       " 'behavior',\n",
       " 'transcriptomic',\n",
       " 'interrelationship',\n",
       " 'psychiatric',\n",
       " 'esophageal',\n",
       " 'plea',\n",
       " 'benefit',\n",
       " 'facilitators',\n",
       " 'explantation',\n",
       " 'incontinence',\n",
       " 'attenuation',\n",
       " 'precursor',\n",
       " 'breast',\n",
       " 'facilitation',\n",
       " 'hemangioma',\n",
       " 'either',\n",
       " 'clenbuterol',\n",
       " 'illness',\n",
       " 'neuronal',\n",
       " 'noninvasive',\n",
       " 'hypothalamic',\n",
       " 'tachycardia',\n",
       " 'biology',\n",
       " 'ca',\n",
       " 'proarrhythmic',\n",
       " 'successfully',\n",
       " 'proactive',\n",
       " 'administer',\n",
       " 'hydrogen',\n",
       " 'hemostasis',\n",
       " 'factor',\n",
       " 'activation',\n",
       " 'candidate',\n",
       " 'seven',\n",
       " 'mecarbil',\n",
       " 'symptomatic',\n",
       " 'sheep',\n",
       " 'leak',\n",
       " 'registries',\n",
       " 'modification',\n",
       " 'interaction',\n",
       " 'biological',\n",
       " 'sociodemographic',\n",
       " 'optimize',\n",
       " 'restrictive',\n",
       " 'waist',\n",
       " 'static',\n",
       " 'septic',\n",
       " 'thrombolysis',\n",
       " 'coarctation',\n",
       " 'college',\n",
       " 'cohorts',\n",
       " 'ion',\n",
       " 'drugs',\n",
       " 'urinary',\n",
       " 'africa',\n",
       " 'crosstalk',\n",
       " 'icds',\n",
       " 'differently',\n",
       " 'sleepiness',\n",
       " 'help',\n",
       " 'inhibitor',\n",
       " 'normalize',\n",
       " 'rho',\n",
       " 'zone',\n",
       " 'oscillatory',\n",
       " 'pathologies',\n",
       " 'slope',\n",
       " 'basal',\n",
       " 'camkii',\n",
       " 'afterload',\n",
       " 'course',\n",
       " 'jarvik',\n",
       " 'myogenic',\n",
       " 'regulatory',\n",
       " 'glenn',\n",
       " 'implementation',\n",
       " 'occult',\n",
       " 'mellitus',\n",
       " 'mimic',\n",
       " 'accelerate',\n",
       " 'replacement',\n",
       " 'lesion',\n",
       " 'operations',\n",
       " 'increase',\n",
       " 'roles',\n",
       " 'hospitalization',\n",
       " 'average',\n",
       " 'cytoskeletal',\n",
       " 'prognosis',\n",
       " 'standardize',\n",
       " 'decision',\n",
       " 'gain',\n",
       " 'cardia',\n",
       " 'osteosarcoma',\n",
       " 'myoblast',\n",
       " 'affairs',\n",
       " 'focal',\n",
       " 'torsion',\n",
       " 'narrow',\n",
       " 'scores',\n",
       " 'hyperuricemia',\n",
       " 'torasemide',\n",
       " 'report',\n",
       " 'social',\n",
       " 'derivation',\n",
       " 'infective',\n",
       " 'third',\n",
       " 'inos',\n",
       " 'deteriorate',\n",
       " 'cutaneous',\n",
       " 'mirna',\n",
       " 'quest',\n",
       " 'border',\n",
       " 'outward',\n",
       " 'flow',\n",
       " 'collaborative',\n",
       " 'lose',\n",
       " 'opinions',\n",
       " 'agents',\n",
       " 'alternans',\n",
       " 'diaphragmatic',\n",
       " 'states',\n",
       " 'usual',\n",
       " 'resource',\n",
       " 'angiotensinogen',\n",
       " 'mri',\n",
       " 'predictors',\n",
       " 'laparoscopic',\n",
       " 'influx',\n",
       " 'revise',\n",
       " 'lupus',\n",
       " 'felodipine',\n",
       " 'therapy',\n",
       " 'innervation',\n",
       " 'indications',\n",
       " 'potentiate',\n",
       " 'throughout',\n",
       " 'neopterin',\n",
       " 'markers',\n",
       " 'holter',\n",
       " 'general',\n",
       " 'interpret',\n",
       " 'mhealth',\n",
       " 'compute',\n",
       " 'ross',\n",
       " 'radial',\n",
       " 'sulfonylurea',\n",
       " 'style',\n",
       " 'hong',\n",
       " 'v',\n",
       " 'interrupt',\n",
       " 'hypoalbuminemia',\n",
       " 'despite',\n",
       " 'player',\n",
       " 'explanation',\n",
       " 'release',\n",
       " 'moderately',\n",
       " 'particulate',\n",
       " 'subtypes',\n",
       " 'subacute',\n",
       " 'cardiography',\n",
       " 'show',\n",
       " 'withdrawal',\n",
       " 'complexity',\n",
       " 'dystrophy',\n",
       " 'lipopolysaccharide',\n",
       " 'comparative',\n",
       " 'poland',\n",
       " 'signature',\n",
       " 'filter',\n",
       " 'neuropsychological',\n",
       " 'tolerance',\n",
       " 'ecg',\n",
       " 'immunoassay',\n",
       " 'acquisition',\n",
       " 'antithrombotic',\n",
       " 'consultation',\n",
       " 'proatrial',\n",
       " 'mg',\n",
       " 'bs',\n",
       " 'nadph',\n",
       " 'account',\n",
       " 'arch',\n",
       " 'gold',\n",
       " 'estrogen',\n",
       " 'evaluations',\n",
       " 'fistulas',\n",
       " 'current',\n",
       " 'denervation',\n",
       " 'polymorphism',\n",
       " 'distress',\n",
       " 'continuous',\n",
       " 'tolerability',\n",
       " 'adenylate',\n",
       " 'stratification',\n",
       " 'pectoris',\n",
       " 'optimal',\n",
       " 'child',\n",
       " 'prior',\n",
       " 'thalassemia',\n",
       " 'fallot',\n",
       " 'genomic',\n",
       " 'strongly',\n",
       " 'spouses',\n",
       " 'afferents',\n",
       " 'face',\n",
       " 'settings',\n",
       " 'attributable',\n",
       " 'acs',\n",
       " 'stockholm',\n",
       " 'cod',\n",
       " 'valsartan',\n",
       " 'three',\n",
       " 'speed',\n",
       " 'attitudes',\n",
       " 'k',\n",
       " 'witness',\n",
       " 'tell',\n",
       " 'register',\n",
       " 'evolve',\n",
       " 'valvular',\n",
       " 'necrosis',\n",
       " 'cardiogenic',\n",
       " 'volumes',\n",
       " 'warfarin',\n",
       " 'daytime',\n",
       " 'polycystic',\n",
       " 'impella',\n",
       " 'thiazolidinediones',\n",
       " 'acidosis',\n",
       " 'century',\n",
       " 'heart',\n",
       " 'discontinuation',\n",
       " 'baseline',\n",
       " 'carcinoid',\n",
       " 'perindopril',\n",
       " 'admission',\n",
       " 'digital',\n",
       " 'media',\n",
       " 'prostaglandins',\n",
       " 'aliskiren',\n",
       " 'exaggerate',\n",
       " 'italy',\n",
       " 'et',\n",
       " 'neutral',\n",
       " 'anomalies',\n",
       " 'implications',\n",
       " 'satisfaction',\n",
       " 'pollution',\n",
       " 'ductus',\n",
       " 'resistin',\n",
       " 'heparin',\n",
       " 'miniature',\n",
       " 'schedule',\n",
       " 'crt',\n",
       " 'dorsi',\n",
       " 'protein',\n",
       " 'mutant',\n",
       " 'phospholamban',\n",
       " 'toxin',\n",
       " 'human',\n",
       " 'months',\n",
       " 'infiltration',\n",
       " 'interfere',\n",
       " 'angiotensin',\n",
       " 'shock',\n",
       " 'myocardin',\n",
       " 'enzyme',\n",
       " 'resuscitation',\n",
       " 'reverse',\n",
       " 'intermittent',\n",
       " 'circulation',\n",
       " 'also',\n",
       " 'er',\n",
       " 'people',\n",
       " 'posttraumatic',\n",
       " 'hydrops',\n",
       " 'break',\n",
       " 'triangle',\n",
       " 'poor',\n",
       " 'white',\n",
       " 'aged',\n",
       " 'nicardipine',\n",
       " 'mycotic',\n",
       " 'neurohormonal',\n",
       " 'acorn',\n",
       " 'immunomodulation',\n",
       " 'vascular',\n",
       " 'partition',\n",
       " 'barriers',\n",
       " 'postcardiotomy',\n",
       " 'polymorphisms',\n",
       " 'bilateral',\n",
       " 'stay',\n",
       " 'supplementation',\n",
       " 'true',\n",
       " 'tale',\n",
       " 'ros',\n",
       " 'diabetic',\n",
       " 'view',\n",
       " 'ambulatory',\n",
       " 'medicaid',\n",
       " 'vasodilatory',\n",
       " 'cardiometabolic',\n",
       " 'octogenarian',\n",
       " 'minimally',\n",
       " 'fish',\n",
       " 'prolong',\n",
       " 'vagal',\n",
       " 'calpain',\n",
       " 'generate',\n",
       " 'upon',\n",
       " 'lean',\n",
       " 'stemi',\n",
       " 'menopause',\n",
       " 'supportive',\n",
       " 'reference',\n",
       " 'intermacs',\n",
       " 'hamsters',\n",
       " 'development',\n",
       " 'pacemakers',\n",
       " 'myocyte',\n",
       " 'antihypertensive',\n",
       " 'thrombocytopenic',\n",
       " 'fluid',\n",
       " 'promoter',\n",
       " 'arise',\n",
       " 'immersion',\n",
       " 'compliance',\n",
       " 'compromise',\n",
       " 'disparities',\n",
       " 'physiologic',\n",
       " 'mast',\n",
       " 'dahl',\n",
       " 'merit',\n",
       " 'relax',\n",
       " 'ageing',\n",
       " 'art',\n",
       " 'equal',\n",
       " 'isoform',\n",
       " 'computational',\n",
       " 'basis',\n",
       " 'atresia',\n",
       " 'telerehabilitation',\n",
       " 'awake',\n",
       " 'infancy',\n",
       " 'anxiety',\n",
       " 'options',\n",
       " 'asymmetric',\n",
       " 'relaxation',\n",
       " 'indigenous',\n",
       " 'eight',\n",
       " 'urgent',\n",
       " 'capillary',\n",
       " 'inactivation',\n",
       " 'antagonism',\n",
       " 'pathology',\n",
       " 'endogenous',\n",
       " 'compensatory',\n",
       " 'points',\n",
       " 'reaction',\n",
       " 'dilemmas',\n",
       " 'resveratrol',\n",
       " 'primary',\n",
       " 'fenestrated',\n",
       " 'hospice',\n",
       " 'partly',\n",
       " 'molsidomine',\n",
       " 'storage',\n",
       " 'services',\n",
       " 'rather',\n",
       " 'oxidative',\n",
       " 'asv',\n",
       " 'stretch',\n",
       " 'measures',\n",
       " 'indication',\n",
       " 'orthotopic',\n",
       " 'attenuate',\n",
       " 'full',\n",
       " 'synergistic',\n",
       " 'iliac',\n",
       " 'prevalent',\n",
       " 'interval',\n",
       " 'nervosa',\n",
       " 'arrhythmia',\n",
       " 'involvement',\n",
       " 'electrophysiologic',\n",
       " 'adenine',\n",
       " 'red',\n",
       " 'catecholamines',\n",
       " 'adiponectin',\n",
       " 'pitfalls',\n",
       " 'persist',\n",
       " 'range',\n",
       " 'chemosensitivity',\n",
       " 'unravel',\n",
       " 'nitrate',\n",
       " 'economics',\n",
       " 'cor',\n",
       " 'malformation',\n",
       " 'cats',\n",
       " 'acid',\n",
       " 'inodilator',\n",
       " 'ozone',\n",
       " 'variable',\n",
       " 'variants',\n",
       " 'tetrofosmin',\n",
       " 'consumer',\n",
       " 'hemangiomatosis',\n",
       " 'complement',\n",
       " 'posture',\n",
       " 'article',\n",
       " 'ace',\n",
       " 'might',\n",
       " 'stage',\n",
       " 'metastatic',\n",
       " 'vasodilators',\n",
       " 'oxygenation',\n",
       " 'subsequent',\n",
       " 'adipokines',\n",
       " 'aminoterminal',\n",
       " 'appropriate',\n",
       " 'vessel',\n",
       " 'relationship',\n",
       " 'transformation',\n",
       " 'regenerative',\n",
       " 'equations',\n",
       " 'rotary',\n",
       " 'patiromer',\n",
       " 'dopexamine',\n",
       " 'scope',\n",
       " 'anomalous',\n",
       " 'comprehensive',\n",
       " 'urban',\n",
       " 'concepts',\n",
       " 'alternatives',\n",
       " 'area',\n",
       " 'anaemia',\n",
       " 'physicians',\n",
       " 'chemoreceptor',\n",
       " 'amp',\n",
       " 'morphologic',\n",
       " 'parkinson',\n",
       " 'fiber',\n",
       " 'becker',\n",
       " 'thoracotomy',\n",
       " 'acutely',\n",
       " 'comparisons',\n",
       " 'channel',\n",
       " 'group',\n",
       " 'national',\n",
       " 'cycle',\n",
       " 'multiethnic',\n",
       " 'myopathy',\n",
       " 'c',\n",
       " 'condition',\n",
       " 'immunity',\n",
       " 'save',\n",
       " 'surveys',\n",
       " 'everyday',\n",
       " 'cachectic',\n",
       " 'enlarge',\n",
       " 'utilization',\n",
       " 'underlie',\n",
       " 'monitoring',\n",
       " 'removal',\n",
       " 'man',\n",
       " 'locally',\n",
       " 'melatonin',\n",
       " 'progenitors',\n",
       " 'radioimmunoassay',\n",
       " 'hope',\n",
       " 'poly',\n",
       " 'chlorthalidone',\n",
       " 'keep',\n",
       " 'extraction',\n",
       " 'prostaglandin',\n",
       " 'participation',\n",
       " 'alteration',\n",
       " 'st',\n",
       " 'hyperkalaemia',\n",
       " 'phosphorus',\n",
       " 'receive',\n",
       " 'preserve',\n",
       " 'glycation',\n",
       " 'difference',\n",
       " 'step',\n",
       " 'jackson',\n",
       " 'endpoints',\n",
       " 'something',\n",
       " 'duke',\n",
       " 'tumor',\n",
       " 'mice',\n",
       " 'antidiuretic',\n",
       " 'expand',\n",
       " 'include',\n",
       " 'annulus',\n",
       " 'collect',\n",
       " 'losartan',\n",
       " 'dilation',\n",
       " 'injection',\n",
       " 'contractility',\n",
       " 'recognition',\n",
       " 'umbilical',\n",
       " 'week',\n",
       " 'wean',\n",
       " 'anf',\n",
       " 'metalloproteinases',\n",
       " 'always',\n",
       " 'generator',\n",
       " 'programs',\n",
       " 'characteristic',\n",
       " 'calmodulin',\n",
       " 'fetuses',\n",
       " 'commercial',\n",
       " 'synchrony',\n",
       " 'regulators',\n",
       " 'saline',\n",
       " 'isoforms',\n",
       " 'deaths',\n",
       " 'hematologic',\n",
       " 'readmission',\n",
       " 'antagonists',\n",
       " 'year',\n",
       " 'quantitative',\n",
       " 'bucindolol',\n",
       " 'shed',\n",
       " 'reversibility',\n",
       " 'redistribution',\n",
       " 'glomerulonephritis',\n",
       " 'infarctions',\n",
       " 'capture',\n",
       " 'topcat',\n",
       " 'probrain',\n",
       " 'limitations',\n",
       " 'antihypertrophic',\n",
       " 'source',\n",
       " 'arrest',\n",
       " 'splice',\n",
       " 'octogenarians',\n",
       " 'antibody',\n",
       " 'healing',\n",
       " 'central',\n",
       " 'controversies',\n",
       " 'simulate',\n",
       " 'establish',\n",
       " 'connective',\n",
       " 'endurance',\n",
       " 'bioavailability',\n",
       " 'molecules',\n",
       " 'outside',\n",
       " 'ethical',\n",
       " 'culture',\n",
       " 'assign',\n",
       " 'dysfunction',\n",
       " 'manage',\n",
       " 'men',\n",
       " 'excess',\n",
       " 'urocortins',\n",
       " 'equivalent',\n",
       " 'mirnas',\n",
       " 'orifice',\n",
       " 'thalassaemia',\n",
       " 'message',\n",
       " 'annuloplasty',\n",
       " 'education',\n",
       " 'prospects',\n",
       " 'icu',\n",
       " 'clinic',\n",
       " 'injections',\n",
       " 'age',\n",
       " 'proportional',\n",
       " 'intoxication',\n",
       " 'christmas',\n",
       " 'spirituality',\n",
       " 'agreement',\n",
       " 'microvascular',\n",
       " 'neurotrophic',\n",
       " 'collapse',\n",
       " 'suitable',\n",
       " 'lecture',\n",
       " 'hospitalise',\n",
       " 'jet',\n",
       " 'physiological',\n",
       " 'ring',\n",
       " 'framework',\n",
       " 'occlude',\n",
       " 'midterm',\n",
       " 'negative',\n",
       " 'success',\n",
       " 'mild',\n",
       " 'microcirculation',\n",
       " 'insomnia',\n",
       " 'excursion',\n",
       " 'raise',\n",
       " 'expect',\n",
       " 'systematic',\n",
       " 'skilled',\n",
       " 'myofilaments',\n",
       " 'cancer',\n",
       " 'retransplantation',\n",
       " 'model',\n",
       " 'quantity',\n",
       " 'cardiotoxic',\n",
       " 'experience',\n",
       " 'previous',\n",
       " 'vegf',\n",
       " 'mutations',\n",
       " 'sternal',\n",
       " 'bipolar',\n",
       " 'proteins',\n",
       " 'suggest',\n",
       " 'members',\n",
       " 'great',\n",
       " 'sprint',\n",
       " 'xamoterol',\n",
       " 'rates',\n",
       " 'doxorubicin',\n",
       " 'several',\n",
       " 'dependent',\n",
       " 'audit',\n",
       " 'malignant',\n",
       " 'panel',\n",
       " 'path',\n",
       " 'ovarian',\n",
       " 'coexist',\n",
       " 'pediatric',\n",
       " 'guanosine',\n",
       " 'classification',\n",
       " 'context',\n",
       " 'conundrum',\n",
       " 'nitrates',\n",
       " 'phenomenon',\n",
       " 'sense',\n",
       " 'mass',\n",
       " 'alzheimer',\n",
       " 'process',\n",
       " 'distensibility',\n",
       " 'variant',\n",
       " 'periphery',\n",
       " 'large',\n",
       " 'septal',\n",
       " 'extremity',\n",
       " 'fabry',\n",
       " 'camp',\n",
       " 'stiffen',\n",
       " 'isotonic',\n",
       " 'solve',\n",
       " 'offer',\n",
       " 'making',\n",
       " 'load',\n",
       " 'multidimensional',\n",
       " 'oxidases',\n",
       " 'truncus',\n",
       " 'along',\n",
       " 'homecare',\n",
       " 'dismutase',\n",
       " 'postconditioning',\n",
       " 'scleroderma',\n",
       " 'exhaustion',\n",
       " 'shenfu',\n",
       " 'rheumatoid',\n",
       " 'tilt',\n",
       " 'arteritis',\n",
       " 'inr',\n",
       " 'escape',\n",
       " 'beijing',\n",
       " 'quantification',\n",
       " 'chemoattractant',\n",
       " 'regress',\n",
       " 'associations',\n",
       " 'discussion',\n",
       " 'sternotomy',\n",
       " 'relevant',\n",
       " 'transfusion',\n",
       " 'countries',\n",
       " 'specialists',\n",
       " 'antiinflammatory',\n",
       " 'study',\n",
       " 'sarcomeric',\n",
       " 'genetic',\n",
       " 'may',\n",
       " 'simulations',\n",
       " 'cholinergic',\n",
       " 'families',\n",
       " 'intervals',\n",
       " 'one',\n",
       " 'emphasis',\n",
       " 'live',\n",
       " 'immunodeficiency',\n",
       " 'kinases',\n",
       " 'validity',\n",
       " 'multiple',\n",
       " 'modifiable',\n",
       " 'aberrant',\n",
       " 'potassium',\n",
       " 'effectively',\n",
       " 'endopeptidase',\n",
       " 'alcoholic',\n",
       " 'trauma',\n",
       " 'explanted',\n",
       " 'train',\n",
       " 'medicine',\n",
       " 'residential',\n",
       " 'inflammatory',\n",
       " 'nephrectomy',\n",
       " 'dissect',\n",
       " 'cpap',\n",
       " 'telephonic',\n",
       " 'takotsubo',\n",
       " 'resources',\n",
       " 'due',\n",
       " 'noncardiovascular',\n",
       " 'diagnosis',\n",
       " 'light',\n",
       " 'latest',\n",
       " 'mediate',\n",
       " 'transitional',\n",
       " 'chagasic',\n",
       " 'dopaminergic',\n",
       " 'introduction',\n",
       " 'subanalysis',\n",
       " 'ethnicity',\n",
       " 'signaling',\n",
       " 'inhibit',\n",
       " 'lymphoblastic',\n",
       " 'trajectories',\n",
       " 'objectives',\n",
       " 'antagonist',\n",
       " 'tomography',\n",
       " 'artery',\n",
       " 'signal',\n",
       " 'aldehyde',\n",
       " 'magnetically',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words =list(set(words))\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.24326706"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [unique_words.index(x) for x in title_df['title'][1]]\n",
    "np.sum(embed_mat[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1, 20)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(embed_mat)\n",
    "    kmeanModel.fit(embed_mat)\n",
    "    distortions.append(sum(np.min(cdist(embed_mat, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / len(embed_mat))\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 10\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(embed_mat)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE for Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = set(words)\n",
    "words_df = pd.DataFrame(list(w), columns=['words']) \n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df['cluster'] = model.fit_predict(embed_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs = []\n",
    "for row,cluster in words_df[['cluster']].T.iteritems():\n",
    "    val = np.array(cluster)\n",
    "    #cluster = max(val)\n",
    "    for item in val:\n",
    "        if  item == 0:\n",
    "            grp =  'navy'\n",
    "        elif item == 1:\n",
    "            grp =  'green'\n",
    "        elif item == 2:\n",
    "            grp = 'firebrick'\n",
    "        elif item == 3:\n",
    "            grp = 'mediumslateblue'\n",
    "        elif item == 4:\n",
    "            grp = 'darkgoldenrod'\n",
    "        elif item == 5:\n",
    "            grp = 'deepskyblue'\n",
    "        elif item == 6:\n",
    "            grp = 'red'\n",
    "        elif item == 7:\n",
    "            grp = 'yellowgreen'\n",
    "        elif item == 8:\n",
    "            grp = 'yellow'\n",
    "        elif item == 9:\n",
    "            grp = 'violet'\n",
    "    clrs.append(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(embed_mat)\n",
    "Xtsne2d = TSNE(n_components=2).fit_transform(data)\n",
    "Xtsne2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = np.min(Xtsne2d, axis=0), np.max(Xtsne2d, axis=0)\n",
    "Xtsne2d = (Xtsne2d - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtsne2d[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PN = Xtsne2d.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2d =[]\n",
    "Y2d = []\n",
    "for i in range(PN):\n",
    "    X2d.append(Xtsne2d[i][0])\n",
    "    Y2d.append(Xtsne2d[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = [12,10])\n",
    "plt.grid(True)\n",
    "#plt.axhline(y=0, color='k')\n",
    "#plt.axvline(x=0, color='k')\n",
    "plt.title('Two dimensional manifold of ICD 11 Cardiovascular Disease Titles')\n",
    "plt.xlabel(\"Dimension 1\", fontsize=20)\n",
    "plt.ylabel(\"Dimension 2\", fontsize=20)\n",
    "plt.scatter(X2d,Y2d,color = clrs, marker ='.')\n",
    "#plt.savefig('tSNE2d.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
